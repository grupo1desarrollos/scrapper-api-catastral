version: '3.8'

services:
  rosario-scraper-api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: rosario-scraper-api
    restart: unless-stopped
    ports:
      - "5000:5000"

    environment:
      - PYTHONPATH=/app
      - CHROMEDRIVER_PATH=/usr/local/bin/chromedriver
      - DISPLAY=:99
      - FLASK_ENV=production
      - FLASK_APP=app.py
    volumes:
      # Persistir archivos generados
      - ./output:/app/output
      # Logs
      - ./logs:/app/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - SYS_ADMIN  # Necesario para Chrome
    shm_size: 2gb  # Necesario para Chrome
    networks:
      - rosario-scraper-network

networks:
  rosario-scraper-network:
    driver: bridge

volumes:
  output_data:
    driver: local
  logs_data:
    driver: local